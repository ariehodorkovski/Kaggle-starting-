{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Загружаем специальный удобный инструмент для разделения датасета:\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('main_task.csv')\n",
    "df_test = pd.read_csv('kaggle_task.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = data.Rating.mean() # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "df = df_test.append(data, sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Restaurant_id','Name', 'City','Cuisine_Style','Ranking','Price_Range','Num_Rev','Reviews','URL_TA','ID_TA','sample','Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with nans in number of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number_of_Reviews_isNAN'] = pd.isna(df['Num_Rev']).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with nans in price range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_price_range']=df.Price_Range.apply(lambda x: 0 if x in ['$','$$ - $$$','$$$$'] else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummy variables for price range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cheap']=df.Price_Range.apply(lambda x: 1 if x=='$' else 0)\n",
    "df['average_price']=df.Price_Range.apply(lambda x: 1 if x=='$$ - $$$' else 0)\n",
    "df['expencive']=df.Price_Range.apply(lambda x: 1 if x=='$$$$' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processing price_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_convert1(s):\n",
    "    if s=='$':\n",
    "        return 1\n",
    "    elif s=='$$ - $$$':\n",
    "        return 2\n",
    "    elif s=='$$$$':\n",
    "        return 3\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['New_Price_Range']=df.Price_Range.apply(price_convert1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling nans in Number Of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Num_Rev.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since there is different amount of reviews in cities \n",
    "//number of reviews - mean for city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_num_rev = df.groupby(['City'])['Num_Rev'].mean()\n",
    "df['city_num_rev'] = df.City.apply(lambda x: city_num_rev[x])\n",
    "df['New_Num_Rev_City']=df.Num_Rev-df['city_num_rev']\n",
    "df=df.drop(['city_num_rev'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since there is different amount of reviews in price ranges //number of reviews - mean for price range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_num_rev = df.groupby(['New_Price_Range'])['Num_Rev'].mean()\n",
    "df['pr_num_rev'] = df.New_Price_Range.apply(lambda x: pr_num_rev[x])\n",
    "df['New_Num_Rev_pr']=df.Num_Rev-df.pr_num_rev\n",
    "df=df.drop(['pr_num_rev'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of cities, countries and capitals transforming to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities=[]\n",
    "for s in df.City:\n",
    "    if s not in cities:\n",
    "        cities.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_city(s):\n",
    "    if city in s:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in cities:\n",
    "    df[city]=df.City.apply(contain_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {'Italy': ['Rome', 'Milan'], 'Germany': ['Berlin', 'Munich', 'Hamburg'], 'Switzerland': ['Geneva', 'Zurich'], 'Portugal': ['Lisbon', 'Oporto'], 'UK': ['London','Edinburgh'], 'Poland': ['Warsaw', 'Krakow'], 'France': ['Paris', 'Lyon'], 'Spain': ['Madrid', 'Barcelona']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country(s):\n",
    "    for i in countries:\n",
    "        if s in countries[i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country']=df.City.apply(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'].fillna('one_city', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_country=['Italy','Germany','Switzerland','Portugal','UK','Poland','France','Spain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_country(s):\n",
    "    if country in s:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in unique_country:\n",
    "    df[country]=df.country.apply(dummy_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitals(s):\n",
    "    capitals=['Paris', 'Stockholm', 'London', 'Berlin',\n",
    "       'Bratislava', 'Vienna', 'Rome', 'Madrid',\n",
    "       'Dublin', 'Brussels', 'Warsaw', 'Budapest', 'Copenhagen',\n",
    "       'Amsterdam', 'Lisbon', 'Prague', 'Oslo',\n",
    "       'Helsinki', 'Edinburgh',  'Ljubljana', 'Athens',\n",
    "       'Luxembourg']\n",
    "    if s in capitals:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital']=df.City.apply(capitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eastern or western europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easwesteurope(s):\n",
    "    easteurope = ['Bratislava', 'Warsaw', 'Budapest', 'Prague', 'Ljubljana', 'Krakow']\n",
    "    if s in easteurope:\n",
    "        return 1\n",
    "    return 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['East/West_europe']=df.City.apply(easwesteurope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Famous tourist cities according to Tripadvisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tourist_favorite(s):\n",
    "    tour_fav=['Paris', 'London', 'Rome', 'Barcelona', 'Prague', 'Lisbon', 'Amsterdam', 'Budapest', 'Berlin', 'Edinburgh', 'Vienna', 'Krakow']\n",
    "    if s in tour_fav:\n",
    "        return 1\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tourist_city']=df.City.apply(tourist_favorite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cities with most 5 starred restrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_5(s):\n",
    "    cities5 = ['Milan', 'Berlin', 'Madrid', 'Paris', 'London', 'Barcelona', 'Rome']\n",
    "    if s in cities5:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_rest_cities']=df.City.apply(most_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cities with worst mean star ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worst4(s):\n",
    "    worst=['Madrid','Milan','Stockholm','Oslo']\n",
    "    if s in worst:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['worst4']=df.City.apply(worst4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding population from Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "populations={'Paris':2140526,\n",
    " 'Stockholm':972647,\n",
    " 'London':8908081,\n",
    " 'Berlin':3748148,\n",
    " 'Munich':1471508,\n",
    " 'Oporto':287591,\n",
    " 'Milan':1395274,\n",
    " 'Bratislava':424428,\n",
    " 'Vienna':1888776,\n",
    " 'Rome':2872800,\n",
    " 'Barcelona':1620343,\n",
    " 'Madrid':3223334,\n",
    " 'Dublin':554554,\n",
    " 'Brussels':1191604,\n",
    " 'Zurich':415215,\n",
    " 'Warsaw':1783321,\n",
    " 'Budapest':1750268,\n",
    " 'Copenhagen':1000218,\n",
    " 'Amsterdam':866737,\n",
    " 'Lyon':513275,\n",
    " 'Hamburg':1822445,\n",
    " 'Lisbon':505526,\n",
    " 'Prague':1308632,\n",
    " 'Oslo':690335,\n",
    " 'Helsinki':650058,\n",
    " 'Edinburgh':488050,\n",
    " 'Geneva':201741,\n",
    " 'Ljubljana':292988,\n",
    " 'Athens':664046,\n",
    " 'Luxembourg':613894,\n",
    " 'Krakow':762508}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population1(s):\n",
    "    for i in populations:\n",
    "        if s == i:\n",
    "            return populations[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['population']=df.City.apply(population1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding area sizes of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_size= {'London': 1575, 'Paris': 105.4, 'Madrid':  608, 'Barcelona': 100.4, 'Berlin': 3891.9,\n",
    "           'Milan': 182, 'Rome': 1285.3, 'Prague': 496, 'Lisbon': 83.84, 'Vienna': 414.9, 'Amsterdam':219.3,\n",
    "                'Munich': 310.4, 'Hamburg': 755.3, 'Brussels': 161.38, 'Stockholm': 414, 'Budapest': 525.1,\n",
    "                'Warsaw': 517.24, 'Copenhagen':  88.25, 'Dublin': 115, 'Lyon': 47.9, 'Athens': 38,\n",
    "                'Edinburgh': 259, 'Zurich': 87.9, 'Oporto': 41.3, 'Geneva': 15.9, 'Krakow': 326.8, \n",
    "                'Helsinki': 213.75, 'Oslo': 454, 'Bratislava': 367.6, 'Luxembourg': 51.7, 'Ljubljana': 275}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(s):\n",
    "    for i in area_size:\n",
    "        if s == i:\n",
    "            return area_size[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area_size']=df.City.apply(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation function for cusines and fiiling no cusine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_prep(s):\n",
    "    s=s[2:-2]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Cuisine_Style=df.Cuisine_Style.fillna(\"['no_cusine']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting set of unique cusines and processing them to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_cus=[]\n",
    "def unique_cusine(s):\n",
    "    s=s.split(sep='\\', \\'')\n",
    "    for x in range(len(s)):\n",
    "        if s[x] not in un_cus:\n",
    "            un_cus.append(s[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Cuisine_Style=df.Cuisine_Style.apply(list_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "5        None\n",
       "6        None\n",
       "7        None\n",
       "8        None\n",
       "9        None\n",
       "10       None\n",
       "11       None\n",
       "12       None\n",
       "13       None\n",
       "14       None\n",
       "15       None\n",
       "16       None\n",
       "17       None\n",
       "18       None\n",
       "19       None\n",
       "20       None\n",
       "21       None\n",
       "22       None\n",
       "23       None\n",
       "24       None\n",
       "25       None\n",
       "26       None\n",
       "27       None\n",
       "28       None\n",
       "29       None\n",
       "         ... \n",
       "49970    None\n",
       "49971    None\n",
       "49972    None\n",
       "49973    None\n",
       "49974    None\n",
       "49975    None\n",
       "49976    None\n",
       "49977    None\n",
       "49978    None\n",
       "49979    None\n",
       "49980    None\n",
       "49981    None\n",
       "49982    None\n",
       "49983    None\n",
       "49984    None\n",
       "49985    None\n",
       "49986    None\n",
       "49987    None\n",
       "49988    None\n",
       "49989    None\n",
       "49990    None\n",
       "49991    None\n",
       "49992    None\n",
       "49993    None\n",
       "49994    None\n",
       "49995    None\n",
       "49996    None\n",
       "49997    None\n",
       "49998    None\n",
       "49999    None\n",
       "Name: Cuisine_Style, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Cuisine_Style.apply(unique_cusine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_cusine(s):\n",
    "    if cusine in s:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cusine in un_cus:\n",
    "    df[cusine]=df.Cuisine_Style.apply(contain_cusine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of cusines in resturant and dummying it a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cusines_in_rest(s):\n",
    "\n",
    "    if 'no_cusine' in s:\n",
    "        return 0\n",
    "    return len(s)\n",
    "df['cusine_len']=df.Cuisine_Style.apply(cusines_in_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_cusine(s):\n",
    "    if s==1:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_cusines(s):\n",
    "    if s==2:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threeormore_cusines(s):\n",
    "    if s>=3:\n",
    "        return 1\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['One_cusine']=df.cusine_len.apply(one_cusine)\n",
    "df['two_cusines']=df.cusine_len.apply(two_cusines)\n",
    "df['threeormore_cusines']=df.cusine_len.apply(threeormore_cusines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local food dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localfood(s):\n",
    "    if s>=2:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Am_Local']=df['Amsterdam']+df['Dutch']\n",
    "df['Athens_local']=df.Athens+df.Greek\n",
    "df['Brussels_local']=df.Brussels+df.Belgian\n",
    "df['Budapest_local']=df.Budapest+df.Hungarian\n",
    "df['Copenhagen_local']=df.Copenhagen+df.Danish\n",
    "df['Dublin_local']=df.Dublin+df.Irish\n",
    "df['Edinburgh_local']=df.Edinburgh+df.Scottish\n",
    "df['London_local']=df.London+df.British\n",
    "df['Italy_local']=df.Italy+df.Italian\n",
    "df['Germany_local']=df.Germany+df.German\n",
    "df['Portugal_local']=df.Portugal+df.Portuguese\n",
    "df['Poland_local']=df.Poland+df.Polish\n",
    "df['France_local']=df.France+df.French\n",
    "df['Ljubljana_local']=df.Ljubljana+df.Slovenian\n",
    "df['Oslo_local']=df.Oslo+df.Norwegian\n",
    "df['Prague_local']=df.Prague+df.Czech\n",
    "df['Stockholm_local']=df.Stockholm+df.Swedish\n",
    "df['Vienna_local']=df.Vienna+df.Austrian\n",
    "df['Switzerland_local']=df.Switzerland+df.Swiss\n",
    "\n",
    "\n",
    "df.Am_Local=df.Am_Local.apply(localfood)\n",
    "df['Athens_local']=df['Athens_local'].apply(localfood)\n",
    "df['Brussels_local']=df['Brussels_local'].apply(localfood)\n",
    "df['Budapest_local']=df['Budapest_local'].apply(localfood)\n",
    "df['Copenhagen_local']=df['Copenhagen_local'].apply(localfood)\n",
    "df['Dublin_local']=df['Dublin_local'].apply(localfood)\n",
    "df['Edinburgh_local']=df['Edinburgh_local'].apply(localfood)\n",
    "df['London_local']=df['London_local'].apply(localfood)\n",
    "df['Italy_local']=df['Italy_local'].apply(localfood)\n",
    "df['Germany_local']=df['Germany_local'].apply(localfood)\n",
    "df['Portugal_local']=df['Portugal_local'].apply(localfood)\n",
    "df['Poland_local']=df['Poland_local'].apply(localfood)\n",
    "df['France_local']=df['France_local'].apply(localfood)\n",
    "df['Ljubljana_local']=df['Ljubljana_local'].apply(localfood)\n",
    "df['Oslo_local']=df['Oslo_local'].apply(localfood)\n",
    "df['Prague_local']=df['Prague_local'].apply(localfood)\n",
    "df['Stockholm_local']=df['Stockholm_local'].apply(localfood)\n",
    "df['Vienna_local']=df['Vienna_local'].apply(localfood)\n",
    "df['Switzerland_local']=df['Switzerland_local'].apply(localfood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting with reviews / nans and dummying nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reviews'].fillna('[[], []]', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['No_Reviews']=df['Reviews'].apply(lambda x: 1 if x=='[[], []]' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_prep1(s):\n",
    "    s=s[3:-3]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reviews']=df['Reviews'].apply(list_prep1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting dates data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_unix_date(s):\n",
    "    if s=='], [':\n",
    "        return 0\n",
    "    dates = s.split('], [')\n",
    "    if len(dates)>1:\n",
    "        mask = '%m/%d/%Y'\n",
    "        result = re.findall('\\d+/\\d+/\\d+', dates[1])\n",
    "        date1=datetime.strptime(result[0], mask )\n",
    "        return datetime.timestamp(date1)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_comment_date']=df['Reviews'].apply(get_last_unix_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def between_dates(s):\n",
    "    if s=='], [':\n",
    "        return 0\n",
    "    dates = s.split('], [')\n",
    "    if len(dates)>1:\n",
    "        mask = '%m/%d/%Y'\n",
    "        result = re.findall('\\d+/\\d+/\\d+', dates[1])\n",
    "        date1=datetime.strptime(result[0], mask )\n",
    "        if len(result)>1:\n",
    "            date2=datetime.strptime(result[1], mask )\n",
    "            between_dates=date1-date2\n",
    "            return float(abs(between_dates.days))\n",
    "        return 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['between_dates']=df['Reviews'].apply(between_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing reviews for simple word analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rew_prep(s):\n",
    "    if s=='], [':\n",
    "        return nan\n",
    "    s=s.lower()\n",
    "    s= re.sub(r'[^a-zA-Z\\s]', '', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reviews']=df['Reviews'].apply(rew_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've made the vocabularies of words for every rating and separeted related words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc1=['worst', 'terrible', 'poor','bad', 'horrible', 'awful', 'avoid', 'rude', 'disappointing','worse'\n",
    "      ,'disaster','nasty','disappointed','dirty','horrific' ,\n",
    "       'unhygienic', 'hostile', 'cheated', 'dreadful',  'rudely', 'waste', 'unpleasant', 'garbage', 'fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab1(s):\n",
    "    count=0\n",
    "    for x in voc1:\n",
    "        if x in s:\n",
    "            count+=1\n",
    "    return count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Voc1']=df['Reviews'].apply(vocab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc15=['avoid', 'worst', 'expensive', 'rip', 'bad', 'terrible',  'awful', 'disgusting', 'trap', 'horrible', 'overpriced'\n",
    "       , 'poor','ripped', 'rude', 'disappointing','scam','mediocre','shame', 'dreadful','disappointed', 'dishonest', \n",
    "       'nightmare', 'poison','undercooked','inefficient', 'disgraceful' , 'racist', 'thieves','awfull'\n",
    "     , 'cremated', 'horrific', 'poisoned' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab15(s):\n",
    "    count=0\n",
    "    for x in voc15:\n",
    "        if x in s:\n",
    "            count+=1\n",
    "    return count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Voc15']=df['Reviews'].apply(vocab15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc2=[ 'bad', 'poor', 'worst', 'avoid', 'terrible','horrible', 'average','rude', 'expensive', 'disappointing', \n",
    "       'trap','awful', 'overpriced','slow','disappointed','excellent', 'rip','disappointment', \n",
    "       'scam','dreadful', 'disgusting' , 'passable', 'unhelpful', 'rubish' , 'poorly', 'illegal', 'medicore', 'cheater' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab2(s):\n",
    "    count=0\n",
    "    for x in voc2:\n",
    "        if x in s:\n",
    "            count+=1\n",
    "    return count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Voc2']=df['Reviews'].apply(vocab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc25=[ 'good', 'not', 'great', 'nice', 'very', 'average', 'poor', 'worst', 'avoid', 'disappointing', 'dont', 'terrible',\n",
    "       'better', 'awful', 'rude', 'expensive', 'friendly','cheap', 'quality', 'excellent', 'decent' ,'overpriced', 'horrible',\n",
    "       'little', 'tasty', 'delicious', 'slow', 'busy', 'small', 'enough', 'disappointed' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab25(s):\n",
    "    count=0\n",
    "    for x in voc25:\n",
    "        if x in s:\n",
    "            count+=1\n",
    "    return count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Voc25']=df['Reviews'].apply(vocab25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc3=[ 'good', 'great', 'nice', 'very', 'average', 'bad', 'best', 'quick', 'poor', 'worst', 'excellent', 'friendly', 'terrible'\n",
    "       , 'cheap', 'expensive', 'lovely', 'bar', 'decent', 'better', 'tasty', 'slow', 'disappointing', 'fast', 'avoid', 'rude'\n",
    "       'really', 'little', 'quality', 'awful', 'pub', 'overpriced', 'perfect', 'horrible', 'away', 'delicious', 'worth', 'typical',\n",
    "       'reasonable', 'special', 'mediocre', 'small', 'amazing', 'family', 'pricey', 'big', 'well', 'pleasant', 'never', 'busy'\n",
    "       , 'authentic', 'friends', 'disappointed', 'fantastic', 'traditional', 'beautiful', 'fresh', 'hot', 'cosy', 'love'\n",
    "       , 'trap', 'low', 'worse', 'dirty', 'unfriendly', 'cheerful', 'disappointment', 'fine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab3(s):\n",
    "    count=0\n",
    "    for x in voc3:\n",
    "        if x in s:\n",
    "            count+=1\n",
    "    return count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Voc3']=df['Reviews'].apply(vocab3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc35=['good',  'great','nice', 'very', 'average', 'excellent', 'best', 'tasty', 'friendly', 'delicious'\n",
    "       ,'lovely','quick','bad', 'atmosphere','cheap', 'bar', 'decent', 'little', 'local', 'pub', 'quality', 'better', \n",
    "       'poor', 'expensive', 'beer', 'authentic','amazing', 'fast', 'disappointing', 'perfect', 'reasonable', 'pleasant'\n",
    "       'terrible', 'fantastic', 'slow', 'worst', 'wonderful', 'fun', 'cosy', 'late', 'simple', 'traditional',\n",
    "       'overpriced', 'rude', 'okay', 'hidden', 'gem','cozy' , 'typical', 'super'\n",
    "       , 'beautiful', 'quiet', 'awful', 'avoid', 'easy', 'pretty', 'awesome', 'love', 'pricey', 'real' , 'horrible',\n",
    "        'cool', 'enjoyable', 'fair', 'large', 'high', 'happy', 'clean', 'affordable', 'disappointed', 'mediocre',\n",
    "        'recommended', 'yummy', 'expected', 'convenient', 'surprisingly' , 'relaxed', 'fabulous', 'cute', \n",
    "        'reasonably', 'unfriendly', 'welcoming', 'helpful'\n",
    "       , 'usual', 'fare', 'low', 'brilliant', 'outstanding', 'honest', 'favourite', 'charming', 'relaxing', 'variety', 'wow'\n",
    "       , 'absolutely', 'popular', 'comfortable', 'vegan', 'light', 'inexpensive', 'wrong', 'cheerful', 'quaint', 'surprised', 'ideal', \n",
    "       'free', 'meals', 'shame', 'yum', 'incredible', 'vibe', 'rather', 'slightly', 'middle', 'heaven', 'huge', 'fairly', 'recommend'\n",
    "       , 'unique', 'gorgeous', 'boring', 'crowded', 'solid', 'perfectly', 'impressed', 'acceptable', 'overall', 'noisy', \n",
    "       'stylish', 'extremely', 'needed', 'almost', 'waste', 'quirky', 'reliable', 'efficient', 'generous', 'disappointment'\n",
    "       , 'dirty', 'expectations', 'improvement', 'highly', 'unpretentious', 'underwhelming', 'less', 'delightful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab35(s):\n",
    "    count=0\n",
    "    for x in voc35:\n",
    "        if x in s:\n",
    "            count+=1\n",
    "    if count>=1:\n",
    "        return 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Voc35']=df['Reviews'].apply(vocab35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc4=['good', 'great', 'nice', 'very', 'excellent', 'best', 'delicious', 'tasty', 'lovely', 'pizza', 'friendly', 'italian', 'local', 'little'\n",
    "       ,  'bar', 'amazing', 'quick', 'authentic', 'pub', 'sushi', 'coffee', 'really', 'cheap', 'perfect', 'fantastic',\n",
    "       'fresh', 'average', 'decent', 'beer', 'tapas', 'wonderful', 'pleasant', 'small', 'worth', 'bad', 'eat', 'traditional', 'gem', 'fast', 'expensive', \n",
    "       'reasonable' 'burger', 'ok', 'wine', 'fish', 'so', 'cozy', 'indian', 'simple', 'family', 'view', 'cosy', \n",
    "         'chinese', 'better' 'drink', 'surprise', 'fun', 'hidden', 'beautiful', 'like', 'ever', 'japanese'\n",
    "       , 'love', 'old', 'well', 'awesome', 'poor', 'new', 'pasta', 'seafood', 'interesting', 'cool', 'typical',\n",
    "        'slow', 'quiet', 'yummy', 'healthy', 'relaxed', 'friends', 'disappointing', 'fine', \n",
    "        'affordable', 'classic', 'fabulous', 'different', 'overpriced',  'enjoyable', \n",
    "        'charming', 'pretty', 'modern', 'happy', 'welcoming'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab4(s):\n",
    "    count=0\n",
    "    for x in voc4:\n",
    "        if x in s:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Voc4']=df['Reviews'].apply(vocab4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc45=[ 'great', 'good', 'best', 'excellent', 'nice', 'very', 'delicious', 'amazing', 'friendly', 'lovely',\n",
    "      'tasty', 'fantastic', 'little', 'bar', 'wonderful', 'atmosphere' , 'perfect', 'authentic', 'gem', 'local', \n",
    "        'fresh', 'hidden', 'wine',  'awesome', 'cozy', 'small', 'cheap', 'cosy',  'superb', 'quick', 'super'\n",
    "       , 'family', 'love', 'traditional', 'worth', 'surprise', 'fabulous' , 'yummy', 'brilliant', 'beautiful', 'top', 'favourite',  'cool', 'outstanding'\n",
    "       , 'pleasant', 'simple', 'well', 'loved', 'near', 'favorite', 'wow', 'better' , 'decent', 'healthy', 'absolutely', 'fast', 'recommended', 'highly' , 'cute', 'quiet', 'typical', 'reasonable', 'warm'\n",
    "       , 'interesting'\n",
    "       , 'relaxed', 'delightful', 'incredible', 'expensive', 'welcoming', 'relaxing', 'homemade', 'affordable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab45(s):\n",
    "    count=0\n",
    "    for x in voc45:\n",
    "        if x in s:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Voc45']=df['Reviews'].apply(vocab45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc5=['great', 'best', 'good','excellent', 'amazing', 'nice',  'delicious', 'with','very', 'little', 'friendly', 'lovely', 'coffee',\n",
    "      'gem',  'bar', 'fantastic', 'tasty', 'authentic', 'fresh', 'perfect', 'wonderful', 'hidden', 'local', 'wine', 'new','love',\n",
    "      'super', 'awesome',  'fabulous', 'cosy', 'beer', 'cozy',\n",
    "      'small','yummy', 'beautiful', 'highly','surprise','absolutely', 'favourite', 'top','brilliant','recommended','pleasant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab5(s):\n",
    "    count=0\n",
    "    for x in voc5:\n",
    "        if x in s:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Voc5']=df['Reviews'].apply(vocab5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Ranking in dataset is ranking of resturant in particular city,  i decided to make a more realistic ranking for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_mean = df.groupby(['City'])['Ranking'].mean()\n",
    "city_max = df.groupby(['City'])['Ranking'].max()\n",
    "df['rankingmaxcity'] = df['City'].apply(lambda x: city_max[x])\n",
    "city_count= df['City'].value_counts(ascending=False)\n",
    "df['rankingmeancity'] = df['City'].apply(lambda x: city_mean[x])\n",
    "df['rankingincity'] = df['City'].apply(lambda x: city_count[x])\n",
    "df['newranking'] = (df['Ranking'] - df['rankingmeancity']) / df['rankingincity']\n",
    "df['NewRank1']=df['rankingmaxcity']-df['Ranking']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Tripadvisor cite , we know, that ranking strongly related to number of reviews and relevancy of dates for reviews. https://www.tripadvisor.com/TripAdvisorInsights/w765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formula_trip(row):\n",
    "    if int(row['Num_Rev'])>50 and row['last_comment_date']> 1503705600:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['formula_trip']=df.apply(formula_trip, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ranking_Nr_Const']=df.Num_Rev*df['Ranking']\n",
    "df['Ranking_Last_Comment_Const']=df['Ranking']*df['last_comment_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount of resturants for population may contribute to model a bit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rest_per_population']=df.population/df.rankingincity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['rankingmeancity','rankingincity'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to scale the data to avoid overrepresenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "norm=df[['Ranking','Num_Rev','New_Price_Range','cusine_len','between_dates','newranking','population','area_size','rest_per_population','New_Num_Rev_City','New_Num_Rev_pr','Voc1','Voc15','Voc2','Voc25','Voc3','Voc35','Voc45','Voc5','last_comment_date','Voc4','Ranking_Nr_Const','Ranking_Last_Comment_Const','NewRank1','rankingmaxcity']]\n",
    "scaler = StandardScaler() \n",
    "df_scaled = scaler.fit_transform(norm)\n",
    "df[['Ranking','Num_Rev','New_Price_Range','cusine_len','between_dates','newranking','population','area_size','rest_per_population','New_Num_Rev_City','New_Num_Rev_pr','Voc1','Voc15','Voc2','Voc25','Voc3','Voc35','Voc45','Voc5','last_comment_date','Voc4','Ranking_Nr_Const','Ranking_Last_Comment_Const','NewRank1','rankingmaxcity']]=df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Restaurant_id','City','Name','Cuisine_Style','Price_Range','Reviews','URL_TA','ID_TA','country','New_Price_Range'], axis=1)\n",
    "\n",
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = df.query('sample == 1').drop(['sample'], axis=1)\n",
    "\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)\n",
    "\n",
    "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 224), (40000, 223), (32000, 223), (8000, 223))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   23.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Создаём модель\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.19654749999999999\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df.query('sample == 0').drop(['sample'], axis=1)\n",
    "test_data = test_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to round our results for better predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_half(num):\n",
    "    if num < 1.25:\n",
    "        num = 1.0\n",
    "    elif num < 1.75:\n",
    "        num = 1.5\n",
    "    elif num < 2.25:\n",
    "        num = 2\n",
    "    elif num < 2.75:\n",
    "        num = 2.5\n",
    "    elif num < 3.25:\n",
    "        num = 3.0\n",
    "    elif num < 3.75:\n",
    "        num = 3.5\n",
    "    elif num < 4.25:\n",
    "        num = 4.0\n",
    "    elif num < 4.75:\n",
    "        num = 4.5\n",
    "    else:\n",
    "        num = 5.0\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_2</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_4</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant_id  Rating\n",
       "0          id_0     3.0\n",
       "1          id_1     4.0\n",
       "2          id_2     4.5\n",
       "3          id_3     4.5\n",
       "4          id_4     4.5"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['Rating'] = predict_submission\n",
    "sample_submission['Rating']=sample_submission['Rating'].apply(round_half)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
